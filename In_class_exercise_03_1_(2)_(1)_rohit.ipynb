{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MunnaGITAM/Rohit_INFO5731_SPRING2022/blob/main/In_class_exercise_03_1_(2)_(1)_rohit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFUQpqRYde2D"
      },
      "source": [
        "## The third In-class-exercise (2/22/2022, 40 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3luaNQRnde2L"
      },
      "source": [
        "The purpose of this exercise is to understand text representation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mi0CB9jbde2N"
      },
      "source": [
        "Question 1 (10 points): Describe an interesting text classification or text mining task and explain what kind of features might be useful for you to build the machine learning model. List your features and explain why these features might be helpful. You need to list at least five different types of features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3gPjTWude2P"
      },
      "outputs": [],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "I found an interesting topic on text mining called Information Extraction. The main part of the process is feature selection.\n",
        "Feature selection is a procedure in which you automatically choose those characteristics in your data that contribute the most to the prediction variable or output of interest.\n",
        "The presence of irrelevant characteristics in your data can reduce the accuracy of many models, particularly linear methods such as linear and logistic regression.\n",
        "There are many tyeps of features. Some of them are:\n",
        "1: Word Features\n",
        "2: Phrase Patterns\n",
        "3: Numerical Variables\n",
        "4: Categorical variables\n",
        "\n",
        "Here i worked on a dataset with text and we work on some of the processes of Text mining like Tokenization, Feature extraction, removing stop words etc,.\n",
        "\n",
        "Tokenization segments a document into its atomic elements. In this case, we are interested in tokenizing to words. First we need to break the sentence in to words.\n",
        "\n",
        "Finding the frequency count for how many times the word occurs.\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSupsl44de2U"
      },
      "source": [
        "Question 2 (20 points): Write python code to extract these features you discussed above. You can collect a few sample text data for the feature extraction. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXPXDW9Wde2V",
        "outputId": "ee61f5d5-4abf-4924-d496-d77711cb0b04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       0\n",
            "-     39\n",
            "and   36\n",
            ":     34\n",
            "Data  31\n",
            "in    28\n",
            "with  27\n",
            "of    27\n",
            "to    24\n",
            ",     23\n",
            "for   23\n"
          ]
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from wordcloud import WordCloud\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "%matplotlib inline\n",
        "df = pd.read_csv('/content/data_tau_days.csv')\n",
        "df.head()\n",
        "\n",
        "sentence = df[\"title\"][0]\n",
        "#print(sentence)\n",
        "tokens = nltk.wordpunct_tokenize(sentence)\n",
        "#print(tokens)\n",
        "# Let us take all the sentence in the dataframe and tokenize to find the words, \n",
        "# and get a frequency of count of each words\n",
        "frequency_words = {}\n",
        "for data in df['title']:\n",
        "    tokens = nltk.wordpunct_tokenize(data)\n",
        "    for token in tokens:\n",
        "        if token in frequency_words:\n",
        "            count = frequency_words[token]\n",
        "            count = count + 1\n",
        "            frequency_words[token] = count\n",
        "        else:\n",
        "            frequency_words[token] = 1\n",
        "\n",
        "#print(frequency_words) # Let us see the frequency_words for each word occuring\n",
        "\n",
        "freq = pd.DataFrame.from_dict(frequency_words, orient = 'index')\n",
        "print(freq.sort_values(by = 0, ascending=False).head(10))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgW7NnoPde2b"
      },
      "source": [
        "Question 3 (10 points): Use any of the feature selection methods mentioned in this paper \"Deng, X., Li, Y., Weng, J., & Zhang, J. (2019). Feature selection for text classification: A review. Multimedia Tools & Applications, 78(3).\" Select the most important features you extracted above, rank the features based on their importance in the descending order. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2v9wH2E3de2d",
        "outputId": "e561adb0-7a40-438f-f509-798aad360643"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>date</th>\n",
              "      <th>days</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>An Exploration of R, Yelp, and the Search for ...</td>\n",
              "      <td>5 points by Rogerh91 6 hours ago  | discuss</td>\n",
              "      <td>1</td>\n",
              "      <td>exploration,r,yelp,search,good,indian,food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Deep Advances in Generative Modeling</td>\n",
              "      <td>7 points by gwulfs 15 hours ago  | 1 comment</td>\n",
              "      <td>1</td>\n",
              "      <td>deep,advances,generative,modeling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Spark Pipelines: Elegant Yet Powerful</td>\n",
              "      <td>3 points by aouyang1 9 hours ago  | discuss</td>\n",
              "      <td>1</td>\n",
              "      <td>spark,pipelines,elegant,yet,powerful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Shit VCs Say</td>\n",
              "      <td>3 points by Argentum01 10 hours ago  | discuss</td>\n",
              "      <td>1</td>\n",
              "      <td>shit,vcs,say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Python, Machine Learning, and Language Wars</td>\n",
              "      <td>4 points by pmigdal 17 hours ago  | discuss</td>\n",
              "      <td>1</td>\n",
              "      <td>python,machine,learning,language,wars</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  \\\n",
              "0  An Exploration of R, Yelp, and the Search for ...   \n",
              "1               Deep Advances in Generative Modeling   \n",
              "2              Spark Pipelines: Elegant Yet Powerful   \n",
              "3                                       Shit VCs Say   \n",
              "4        Python, Machine Learning, and Language Wars   \n",
              "\n",
              "                                             date  days  \\\n",
              "0     5 points by Rogerh91 6 hours ago  | discuss     1   \n",
              "1    7 points by gwulfs 15 hours ago  | 1 comment     1   \n",
              "2     3 points by aouyang1 9 hours ago  | discuss     1   \n",
              "3  3 points by Argentum01 10 hours ago  | discuss     1   \n",
              "4     4 points by pmigdal 17 hours ago  | discuss     1   \n",
              "\n",
              "                                       tokens  \n",
              "0  exploration,r,yelp,search,good,indian,food  \n",
              "1           deep,advances,generative,modeling  \n",
              "2        spark,pipelines,elegant,yet,powerful  \n",
              "3                                shit,vcs,say  \n",
              "4       python,machine,learning,language,wars  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "#nltk.download('stopwords')\n",
        "\n",
        "stop = stopwords.words('english')\n",
        "stop[0:10]\n",
        "\n",
        "stop.extend(('.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}','/','-'))\n",
        "frequency_words_wo_stop = {}\n",
        "def generate_word_frequency(row):\n",
        "    data = row['title']\n",
        "    tokens = nltk.wordpunct_tokenize(data)\n",
        "    token_list = []\n",
        "    for token in tokens:\n",
        "        if token.lower() not in stop:\n",
        "            token_list.append(token.lower())\n",
        "            if token.lower() in frequency_words_wo_stop:\n",
        "                count = frequency_words_wo_stop[token.lower()]\n",
        "                count = count + 1\n",
        "                frequency_words_wo_stop[token.lower()] = count\n",
        "            else:\n",
        "                frequency_words_wo_stop[token.lower()] = 1\n",
        "    \n",
        "    return ','.join(token_list)\n",
        "\n",
        "df['tokens'] = df.apply(generate_word_frequency,axis=1)\n",
        "df.head()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "In-class-exercise-03-1 (2) (1)_rohit.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}